import os
import shutil
import gzip
import pandas as pd # version 1.4.0
import argparse

### move or copy fastq or fastq.gz files to a new directory structure
def reorg_metagenomics_files(oldPath, newPath):
    
    """FASTQ files generated by MetagenomicsPP pipeline are reorganized by V region 
    obtaining 6 folders (one per V region).

    Example for 3 V regions:
    V2_folder:
        -sample_1_name_V2.fastq
        -sample_2_name_V2.fastq
        -sample_3_name_V2.fastq
    V3_folder:
        -sample_1_name_V3.fastq
        -sample_2_name_V3.fastq
        -sample_3_name_V3.fastq
    V4_folder:
        -sample_1_name_V3.fastq
        -sample_2_name_V3.fastq
        -sample_3_name_V3.fastq
    """

    if not os.path.isdir(newPath):
        os.mkdir(newPath)
        
    ## Read file tree in oldPath and get names of fastq files
    def getFileInfo(oldPath,newPath):
        filesOld,filesNew = [],[]
        v_regions = set()   
        for root, dirs, filenames in os.walk(oldPath):
            for file in filenames:
                if file[-6:].lower() == '.fastq' or file[-9:].lower() == '.fastq.gz':
                    filesOld.append(os.path.join(root,file))
                    f = file.replace('FR.','')
                    v = f.split('.')[1]
                    v_regions.add(v)
                    fNew = f.replace('.' + v,'_' + v)
                    filesNew.append(os.path.join(newPath,v,fNew))
        return filesOld,filesNew,v_regions
    filesOld,filesNew,v_regions = getFileInfo(oldPath,newPath)
    assert len(filesOld), 'no files found in "{}"'.format(oldPath)
            
    ## move files to new location -- obviously faster than copying
    def moveFiles(filesOld,filesNew):
        for fOld,fNew in zip(filesOld,filesNew):
            os.makedirs(os.path.dirname(fNew),exist_ok=True)
            shutil.move(fOld,fNew)
    
    ## execute move
    moveFiles(filesOld,filesNew)
    
    # gzip files
    def gzipFileNames(input_file, gzip_file):
        with open(input_file, 'rb') as f_in:
            with gzip.open(gzip_file, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)
                os.remove(input_file)
                 
    for file in filesNew:
        gzipFileNames(file, file + '.gz')

    ## write aggregate counts file
    def aggregate_counts_data(writeFile,oldPath,stats_rows=True):
        # Aggregates total counts from "counts.txt" files in the mainPath directory 
        # tree. File has a row for each sample and a column for each primer.
        # If stats_rows is True, then it will add rows of statistics to the end.
        
        dfs = []
        for root, dirs, filenames in os.walk(oldPath):
            for file in filenames:
                if file == 'counts.txt':
                    dfs.append(pd.read_csv(os.path.join(root,file),sep='\t',
                                           names=['name','count']))
        df = pd.concat(dfs)
        df = df[df['name'] != 'total']
        df = pd.concat((df.name.str.split('.',expand=True),df['count']),axis=1)
        df = df.pivot_table(index=0,columns=1,values='count')
        if stats_rows:
            df = pd.concat((df,df.agg(['mean','std','sem'])))
        df.to_csv(writeFile)

    countsFile = os.path.join(newPath,'total_counts.csv')
    aggregate_counts_data(countsFile,oldPath,stats_rows=True)
    print('\tAggregate counts file written to {}\n'.format(countsFile))   

if __name__ == "__main__":
    #reorg_metagenomics_files(oldPath, newPath)
    print("Reorganizing samples by V region for each run")
    parser = argparse.ArgumentParser(description='Reorganize files by V region')
    parser.add_argument('oldPath', type=str, help='Path to folder where files are organized by sample')
    parser.add_argument('newPath', type=str, help='Path to folder where files will be organized by region')
    
    args = parser.parse_args()

    reorg_metagenomics_files(args.oldPath, args.newPath)